{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T18:20:24.744877Z",
     "iopub.status.busy": "2023-11-08T18:20:24.744485Z",
     "iopub.status.idle": "2023-11-08T18:20:24.751147Z",
     "shell.execute_reply": "2023-11-08T18:20:24.750035Z",
     "shell.execute_reply.started": "2023-11-08T18:20:24.744837Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T18:20:24.757285Z",
     "iopub.status.busy": "2023-11-08T18:20:24.756624Z",
     "iopub.status.idle": "2023-11-08T18:20:24.782478Z",
     "shell.execute_reply": "2023-11-08T18:20:24.781644Z",
     "shell.execute_reply.started": "2023-11-08T18:20:24.757238Z"
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 123] The filename, directory name, or volume label syntax is incorrect: 'D:\\\\ICME2018_Occluded-Person-Reidentification_datasets-master\\\\ICME2018_Occluded-Person-Reidentification_datasets-master\\\\Occ_Small_Dataset\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\HP\\Downloads\\occlusion-reiden (1).ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/occlusion-reiden%20%281%29.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m16\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/occlusion-reiden%20%281%29.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m train_datagen \u001b[39m=\u001b[39m ImageDataGenerator(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/occlusion-reiden%20%281%29.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     rescale\u001b[39m=\u001b[39m\u001b[39m1.\u001b[39m\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/occlusion-reiden%20%281%29.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     rotation_range\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/occlusion-reiden%20%281%29.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     preprocessing_function\u001b[39m=\u001b[39mpreprocess_input\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/occlusion-reiden%20%281%29.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/occlusion-reiden%20%281%29.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m train_generator \u001b[39m=\u001b[39m train_datagen\u001b[39m.\u001b[39;49mflow_from_directory(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/occlusion-reiden%20%281%29.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     train_data_dir,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/occlusion-reiden%20%281%29.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     target_size\u001b[39m=\u001b[39;49m(\u001b[39m150\u001b[39;49m, \u001b[39m150\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/occlusion-reiden%20%281%29.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/occlusion-reiden%20%281%29.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     class_mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcategorical\u001b[39;49m\u001b[39m'\u001b[39;49m  \u001b[39m# Assuming you have multiple classes (persons)\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/occlusion-reiden%20%281%29.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/Downloads/occlusion-reiden%20%281%29.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m test_datagen \u001b[39m=\u001b[39m ImageDataGenerator(rescale\u001b[39m=\u001b[39m\u001b[39m1.\u001b[39m\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\preprocessing\\image.py:1649\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1562\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflow_from_directory\u001b[39m(\n\u001b[0;32m   1563\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1564\u001b[0m     directory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1578\u001b[0m     keep_aspect_ratio\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1579\u001b[0m ):\n\u001b[0;32m   1580\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[0;32m   1581\u001b[0m \n\u001b[0;32m   1582\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m \u001b[39m        and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[0;32m   1648\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1649\u001b[0m     \u001b[39mreturn\u001b[39;00m DirectoryIterator(\n\u001b[0;32m   1650\u001b[0m         directory,\n\u001b[0;32m   1651\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1652\u001b[0m         target_size\u001b[39m=\u001b[39;49mtarget_size,\n\u001b[0;32m   1653\u001b[0m         color_mode\u001b[39m=\u001b[39;49mcolor_mode,\n\u001b[0;32m   1654\u001b[0m         keep_aspect_ratio\u001b[39m=\u001b[39;49mkeep_aspect_ratio,\n\u001b[0;32m   1655\u001b[0m         classes\u001b[39m=\u001b[39;49mclasses,\n\u001b[0;32m   1656\u001b[0m         class_mode\u001b[39m=\u001b[39;49mclass_mode,\n\u001b[0;32m   1657\u001b[0m         data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_format,\n\u001b[0;32m   1658\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1659\u001b[0m         shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1660\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[0;32m   1661\u001b[0m         save_to_dir\u001b[39m=\u001b[39;49msave_to_dir,\n\u001b[0;32m   1662\u001b[0m         save_prefix\u001b[39m=\u001b[39;49msave_prefix,\n\u001b[0;32m   1663\u001b[0m         save_format\u001b[39m=\u001b[39;49msave_format,\n\u001b[0;32m   1664\u001b[0m         follow_links\u001b[39m=\u001b[39;49mfollow_links,\n\u001b[0;32m   1665\u001b[0m         subset\u001b[39m=\u001b[39;49msubset,\n\u001b[0;32m   1666\u001b[0m         interpolation\u001b[39m=\u001b[39;49minterpolation,\n\u001b[0;32m   1667\u001b[0m         dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype,\n\u001b[0;32m   1668\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\preprocessing\\image.py:563\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[0;32m    562\u001b[0m     classes \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 563\u001b[0m     \u001b[39mfor\u001b[39;00m subdir \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(directory)):\n\u001b[0;32m    564\u001b[0m         \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    565\u001b[0m             classes\u001b[39m.\u001b[39mappend(subdir)\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 123] The filename, directory name, or volume label syntax is incorrect: 'D:\\\\ICME2018_Occluded-Person-Reidentification_datasets-master\\\\ICME2018_Occluded-Person-Reidentification_datasets-master\\\\Occ_Small_Dataset\\train'"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "train_data_dir = 'D:/ICME2018_Occluded-Person-Reidentification_datasets-master/ICME2018_Occluded-Person-Reidentification_datasets-master/Occ_Small_Dataset/train'  # Update this path\n",
    "test_data_dir = 'D:/ICME2018_Occluded-Person-Reidentification_datasets-master/ICME2018_Occluded-Person-Reidentification_datasets-master/Occ_Small_Dataset/test'    # Update this path\n",
    "input_shape = (150, 150, 3)\n",
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  # Assuming you have multiple classes (persons)\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T18:20:24.784946Z",
     "iopub.status.busy": "2023-11-08T18:20:24.784241Z",
     "iopub.status.idle": "2023-11-08T18:20:24.798620Z",
     "shell.execute_reply": "2023-11-08T18:20:24.797538Z",
     "shell.execute_reply.started": "2023-11-08T18:20:24.784916Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoding for test data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Use 'categorical' for one-hot encoding\n",
    "    shuffle=False  # Important: Do not shuffle test data\n",
    ")\n",
    "num_classes = train_generator.num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T18:20:24.800142Z",
     "iopub.status.busy": "2023-11-08T18:20:24.799778Z",
     "iopub.status.idle": "2023-11-08T18:20:25.026012Z",
     "shell.execute_reply": "2023-11-08T18:20:25.025128Z",
     "shell.execute_reply.started": "2023-11-08T18:20:24.800113Z"
    }
   },
   "outputs": [],
   "source": [
    "# CNN model construction\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))  # num_classes is the number of persons\n",
    "\n",
    "# Compile the model with accuracy as the metric\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T18:20:25.027671Z",
     "iopub.status.busy": "2023-11-08T18:20:25.027362Z",
     "iopub.status.idle": "2023-11-08T18:20:28.886797Z",
     "shell.execute_reply": "2023-11-08T18:20:28.885738Z",
     "shell.execute_reply.started": "2023-11-08T18:20:25.027644Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(train_generator, steps_per_epoch=train_generator.n // batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T18:20:28.889635Z",
     "iopub.status.busy": "2023-11-08T18:20:28.889124Z",
     "iopub.status.idle": "2023-11-08T18:20:29.218773Z",
     "shell.execute_reply": "2023-11-08T18:20:29.218034Z",
     "shell.execute_reply.started": "2023-11-08T18:20:28.889606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "evaluation = model.evaluate(test_generator, steps=len(test_generator))\n",
    "test_loss, test_accuracy = evaluation[0], evaluation[1]\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T18:22:47.391437Z",
     "iopub.status.busy": "2023-11-08T18:22:47.390272Z",
     "iopub.status.idle": "2023-11-08T18:22:48.363583Z",
     "shell.execute_reply": "2023-11-08T18:22:48.362057Z",
     "shell.execute_reply.started": "2023-11-08T18:22:47.391395Z"
    }
   },
   "outputs": [],
   "source": [
    "# Image plotting\n",
    "def plot_person_images(person_id):\n",
    "    occluded_images = []\n",
    "    full_body_images = []\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(len(test_generator)):\n",
    "        batch = test_generator[i]\n",
    "        images, labels = batch\n",
    "        predicted_classes = model.predict(images)\n",
    "        \n",
    "        occluded_indices = np.where(labels[:, person_id] == 1)[0]\n",
    "        occluded_images.extend(images[occluded_indices])\n",
    "        full_body_indices = np.where(labels[:, person_id] == 0)[0]\n",
    "        full_body_images.extend(images[full_body_indices])\n",
    "        predictions.extend(np.argmax(predicted_classes, axis=1))\n",
    "        \n",
    "    plt.figure(figsize=(18, 8))\n",
    "    for i in range(len(occluded_images)):\n",
    "        plt.subplot(2, len(occluded_images), i + 1)\n",
    "        plt.imshow(occluded_images[i])\n",
    "        plt.title(f'Occluded Image\\nPredicted: Person {predictions[i]}')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(2, len(full_body_images), len(full_body_images) + i + 1)\n",
    "        plt.imshow(full_body_images[i])\n",
    "        plt.title(f'Full Body Image\\nPredicted: Person {predictions[i]}')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Plot images for a random person ID\n",
    "random_person_id = np.random.randint(0, num_classes)  # Choose a random person ID\n",
    "plot_person_images(random_person_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
